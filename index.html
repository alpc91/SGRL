<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>

<!-- ======================================================================= -->
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>
<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 100%;
  }

  h1 {
    font-weight:300;
    max-width: 100%;
  }

  div {
    max-width: 95%;
    margin:auto;
    padding: 10px;
  }

  .table-like {
    display: flex;
    flex-wrap: wrap;
    flex-flow: row wrap;
    justify-content: center;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img {
    padding: 0;
    display: block;
    margin: 0 auto;
    max-height: 100%;
    max-width: 100%;
  }

  table {
    padding: 0;
    display: block;
    margin: 0 auto;
    max-height: 100%;
    max-width: 100%;
  }

  iframe {
    max-width: 100%;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    max-width: 1100px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }

  #authors td {
    padding-bottom:5px;
    padding-top:30px;
  }
</style>
<!-- ======================================================================= -->

<!-- Start : Google Analytics Code -->
<!-- <script async src="https://www.googletagmanager.com/gtag/js?id=UA-64069893-4"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-64069893-4');
</script> -->
<!-- End : Google Analytics Code -->

<script type="text/javascript" src="resources/hidebib.js"></script>
<link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic' rel='stylesheet' type='text/css'>
<head>
<div max-width=100%>
  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <link rel="shortcut icon" href="https://www.cs.cmu.edu/sites/default/files/favicon_0.ico" type="image/vnd.microsoft.icon">
  <title>Subequivariant Graph Reinforcement Learning in 3D Environment</title>
  <meta name="HandheldFriendly" content="True" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <link rel="canonical" href="https://alpc91.github.io/SGRL/" />
  <meta name="referrer" content="no-referrer-when-downgrade" />

  <meta property="og:site_name" content="Subequivariant Graph Reinforcement Learning in 3D Environment" />
  <meta property="og:type" content="video.other" />
  <meta property="og:title" content="Subequivariant Graph Reinforcement Learning in 3D Environment" />
  <meta property="og:description" content="Chen, Han, Sun, Huang. Subequivariant Graph Reinforcement Learning in 3D Environment. ICML 2023 Oral." />
  <meta property="og:url" content="https://alpc91.github.io/SGRL/" />
  <meta property="og:image" content="https://alpc91.github.io/SGRL/resources/teaser.pdf" />
  <meta property="og:image:secure" content="https://alpc91.github.io/SGRL/resources/teaser.pdf" />
  <!-- <meta property="og:video" content="https://www.youtube.com/embed/9YiZZ_8guq8?rel=0&showinfo=0" />
  <meta property="og:video:secure" content="https://www.youtube.com/embed/9YiZZ_8guq8?rel=0&showinfo=0" /> -->

</head>

<body>
      <br>
      <center><span style="font-size:44px;font-weight:bold;">Subequivariant Graph Reinforcement Learning<br>in 3D Environment</span></center>
      <div class="table-like" style="justify-content:space-evenly;max-width:900px;margin:auto;">
          <div><center><span style="font-size:24px"><a href="https://scholar.google.com/citations?user=WaeyhikAAAAJ&hl=en" target="_blank">Runfa Chen*</a></span></center>
          <center><span style="font-size:20px">THU CS, THUAI, BNRist</span></center>
          </div>

          <div><center><span style="font-size:24px"><a href="https://scholar.google.com/citations?user=AKppgMAAAAAJ&hl=en" target="_blank">Jiaqi Han*</a></span></center>
          <center><span style="font-size:20px">THU CS, THUAI, BNRist</span></center>
          </div>

          <div><center><span style="font-size:24px"><a href="https://scholar.google.com/citations?user=DbviELoAAAAJ&hl=en" target="_blank">Fuchun Sun</a></span></center>
          <center><span style="font-size:20px">THU CS, THUAI, BNRist, THU-Bosch JCML Center</span></center>
          </div>

          <div><center><span style="font-size:24px"><a href="https://gsai.ruc.edu.cn/addons/teacher/index/info.html?user_id=31&ruccode=ADIIMVRnBzFXMFdnVTAIOw%3D%3D&ln=en" target="_blank">Wenbing Huang</a></span></center>
            <center><span style="font-size:20px">RUC GSAI</span></center>
            </div>
      </div>
      <!-- <table align=center width=600px style="padding-top:0px;padding-bottom:0px">
          <tr>
            <td align=center width=600px><center><span style="font-size:15px">* equal contribution</span></center></td>
          <tr/>
      </table> -->
      <!-- <center><span style="font-size:24px;"><a href='https://icml.cc/Conferences/2023/PosterSchedule'>ICML 2023</a></span></center> -->

      <div class="table-like" style="justify-content:space-evenly;max-width:800px;margin:auto;padding:5px">
        <div><center><span style="font-size:24px"><a href="https://alpc91.github.io/SGRL/">&nbsp;&nbsp;&nbsp;[Paper]</a></span></center></div>
        <div><center><span style="font-size:24px"><a href='https://github.com/alpc91/SGRL'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;[Code]</a></span></center> </div>
        <!-- <div><center><span style="font-size:24px"><a href="https://alpc91.github.io/SGRL/" target="_blank">[Long Oral Talk]</a></span></center> </div> -->
      </div>

      <!-- <center>
      <iframe style="border: 3px solid #EEE;" width="768" height="432" max-width="100%" src="https://alpc91.github.io/SGRL/" frameborder="0" allowfullscreen></iframe></center> -->
      <br>

      <div style="width:1024px; margin:0 auto; text-align=right;">
        Learning a shared policy that guides the locomotion of different agents is of core interest in Reinforcement Learning (RL), which leads to the study of modular RL. However, existing modular RL benchmarks are highly restrictive in the choice of starting point and target point, constraining the movement of the agents within 2D space. In this work, we propose a novel setup for modular RL, dubbed Subequivariant Graph RL in 3D environments (3D-SGRL). Specifically, we first introduce a new set of more practical yet challenging benchmarks in 3D space that allows the agent to have full Degree-of-Freedoms to explore in arbitrary directions starting from arbitrary configurations. Moreover, to optimize the policy over the enlarged state-action space, we propose to inject geometric symmetry, i.e., subequivariance, into the modeling of the policy and Q-function such that the policy can generalize to all directions, improving exploration efficiency. This goal is achieved by a novel SubEquivariant Transformer (SET) that permits expressive message exchange. Finally, we evaluate the proposed method on the proposed benchmarks, where our method consistently and significantly outperforms existing approaches on single-task, multi-task and zero-shot generalization scenarios. Extensive ablations are also conducted to verify our design.
      </div>
      <br><hr>

      <center><h1>SGRL</h1></center>
      <div style="width:1024px; margin:0 auto; text-align=right">
        In spite of the fruitful progress by modular RL, in this work, we identify several critical setups that have been over-simplified in existing benchmarks, giving rise to a limited state/action space such that the obtained policy is unable to explore the entire 3D space. In particular, the agents are assigned a fixed starting point and restricted to move towards a single direction along the x-axis, leading to 2D motions only. Nevertheless, in a more realistic setup as depicted below, the agents would be expected to have full Degree-of-Freedoms (DoFs) to turn and move in arbitrary directions starting from arbitrary configurations. To address the concern, we extend the existing environments to a set of new benchmarks in 3D space, which meanwhile introduces significant challenges to modular RL due to the massive enlargement of the state-action space for policy optimization. 
      </div>
    

      <table align="center" width="1024px"><tbody><tr><td width="1024px">
        <center><a href="resources/teaser_table.pdf"><img src="resources/teaser_table.pdf" width="1024px" ></img></a></center>
        </td></tr></tbody></table>
        <br><hr>
      
      

      <center><h1>SubEquivariant Transformer (SET)</h1></center>
      <div style="width:1024px; margin:0 auto; text-align=right">
        Optimizing the policy in our new setup is prohibitively difficult, and existing modular RL frameworks like SMP, SWAT are observed to be susceptible to getting stuck in the local minima and exhibited poor generalization in our experiments. To this end, we propose to inject geometric symmetry into the design of the policy network to compact the space redundancy in a lossless way. In particular, we restrict the policy network to be subequivariant in two senses: 1. the output action will rotate in the same way as the input state of the agent; 2. the equivariance is partially relaxed to take into account the effect of gravity in the environment. We design SubEquivariant Transformer (SET) with a novel architecture that satisfies the above constraints while also permitting expressive message propagation through self-attention. Upon SET, the action and Q-function could be obtained with desirable symmetries guaranteed. We term our entire task setup and methodology as Subequivariant Graph Reinforcement Learning in 3D Environments (3D-SGRL).

      </div>
      <table align="center" width="1024px"><tbody><tr><td width="1024px">
      <center><a href="resources/main.pdf"><img src = "resources/main.pdf" width="1024px"></img></a><br></center>
      </td></tr></tbody></table>
      <br/><hr>


            <center id="sourceCode"><h1>Source Code</h1></center>
            <div style="width:1024px; margin:0 auto; text-align=right">
            We have released our implementation in PyTorch on the github page. Try our code!
            <center><span style="font-size:28px"><a href='https://github.com/alpc91/SGRL'>[GitHub]</a></span></center>
            </div>
            <br><hr>

      <center><h1>Related Work</h1></center>
      <div style="width:1024px; margin:0 auto; text-align=right">
        Jiaqi Han, Wenbing Huang, Hengbo Ma, Jiachen Li, Joshua B. Tenenbaum, Chuang Gan. Learning Physical Dynamics with Subequivariant Graph Neural Networks. NeurIPS 2022. <a href="https://github.com/hanjq17/SGNN" target="_blank">[website]</a> <a href="https://arxiv.org/pdf/2210.06876.pdf" target="_blank">[paper]</a>
      </div>
      <br/><hr>

    <center><h1>Paper and Bibtex</h1></center>
    <table align=center width=1024px>
    <tr>
    <td width="49%" align=left>
    <a href="xxx"><img style="height:150px" src="resources/thumbnail.jpg"/></a>
    <!-- <center> -->
    <!-- <span style="font-size:20pt"><a href="xxx">[Paper]</a>
    <span style="font-size:20pt"><a href="xxx">[ArXiv]</a> -->
    <!-- <span style="font-size:20pt"><a href="resources/slides.pdf">[Slides]</a></span>
    <span style="font-size:20pt"><a href="resources/poster.pdf">[Poster]</a></span> -->
    <!-- </center> -->
    </td>
    <td width="2%" align=left>
    </td>
    <td width="49%" align=left>
    <span style="font-size:17pt">Runfa Chen*, Jiaqi Han*, Fuchun Sun, Wenbing Huang. <b>Subequivariant Graph Reinforcement Learning in 3D Environment.</b> ICML 2023 Oral.</span><br/>
    <span style="font-size:20pt"><a shape="rect" href="javascript:togglebib('sgrl2023_bib')" class="togglebib">[Bibtex]</a></span>
    </td>
    </tr>
    <tr>
    <td width="30%" align=left>
    </td>
    <td width="6%" align=center>
    </td>
    <td width="64%" align=left>
    <div class="paper" id="sgrl2023_bib">
<pre xml:space="preserve">
@inproceedings{chen2023sgrl,
    Author = {Runfa, Chen and Jiaqi, Han
    and Fuchun, Sun and Wenbing, Huang},
    Title = {Subequivariant Graph Reinforcement Learning in 3D Environment},
    Booktitle = {ICML},
    Year = {2023}
    }
</pre>
                </div>
                </td>
                </tr>
            </table>
          <br><hr>

      <center><h1>Acknowledgements</h1></center>
      <div style="width:1024px; margin:0 auto; text-align=right">
        This work is jointly funded by "New Generation Artificial Intelligence" Key Field Research and Development Plan of Guangdong Province (2021B0101410002), the National Science and Technology Major Project of the Ministry of Science and Technology of China (No.2018AAA0102900), the Sino-German Collaborative Research Project Crossmodal Learning (NSFC 62061136001/DFG TRR169), THU-Bosch JCML center, and the National Natural Science Foundation of China under Grant U22A2057. 
        <br/>We sincerely thank the reviewers for their insightful comments and suggestions that significantly improved our paper's quality. Our heartfelt thanks go to Yu Luo, Tianying Ji, Chengliang Zhong, and Chao Yang for fruitful discussions and support. Finally, Runfa Chen expresses gratitude to his wife, Xia Zhong, for her unwavering love and support.
      </div><br/>

      </table>

<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>
</div>
</body>
</html>
